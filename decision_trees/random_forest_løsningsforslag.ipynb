{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a534f355",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "**Decision trees er all well and good, men der hvor *the real money(tm) er, er i *Random Forest* modeller. Algoritmen for dette er meget simpel:**\n",
    "\n",
    "1. **Træn en helt masse decision trees på din data (gerne ikke særligt dybe decision trees)**\n",
    "2. **Lav en demokratisk afstemning mellem disse decision trees om hvad et nyt datapunkt er**\n",
    "\n",
    "**Dette er vist rimelig simpelt nedenunder:**\n",
    "\n",
    "![](images/random_forest.png)\n",
    "\n",
    "**I denne opgave vil vi prøve at lave predictions på et par datasæt af forskellig kompleksitet, først med et enkelt decision tree, og så med en random forest model.**\n",
    "\n",
    "**Dette er desværre der hvor ML bevæger sig væk fra det vi kan se på en sej måde, og henimod stats på en skærm, men bear with us!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6dc76",
   "metadata": {},
   "source": [
    "## Opgave 1: Random forest og decision trees\n",
    "\n",
    "**Der er et par datasæt samlet her fra forskellige sources:**\n",
    "\n",
    "- Insurance: [https://www.kaggle.com/datasets/mirichoi0218/insurance](https://www.kaggle.com/datasets/mirichoi0218/insurance)\n",
    "- Iris: [https://www.kaggle.com/datasets/uciml/iris](https://www.kaggle.com/datasets/uciml/iris)\n",
    "\n",
    "**1.1: Lige nu er alle cellerne nedenunder sat til at lave træne en decision tree regressor or en random forest regressor på insurance datasættet. Skift dette fra dette datasæt til en af de andre. Her skal du nok overveje de følgende ting for at få koden til at virke:**\n",
    "\n",
    "- **1. Er det klassifikation eller regression?**\n",
    "- **2. Hvad hedder target kolonnen?**\n",
    "- **3. Er der nogle kolonner som ikke er numeriske? Altså derfor kategoriske?**\n",
    "\n",
    "**1.2: Random forest plejer at have OK performance, men den vælges primært fordi den er *explainable*, altså den kan give et præcist estimat for hvor sikker den er på en given prediction. Forklar hvorfor dette er tilfældet**\n",
    "\n",
    " <span style=\"color:red\">LØSNINGSFORSLAG: Med mange decision trees der \"stemmer\" internt om hvad et datapunkt, kan du få et rimelig godt estimat for hvor sikker hele modellen er. Jo flere træer som er enige om samme beslutning, jo mere sikker må hele modellen være.</span>.\n",
    "\n",
    "**1.3: Overvej tilfælde her hvor et enkeklt decision tree måske ville give mere mening end en hel random forest**\n",
    "\n",
    " <span style=\"color:red\">LØSNINGSFORSLAG: Allerede med insurance datasættet klarer både random forest og decision trees sig godt nok... Hvis compute er en stor ting man er bange for, kunne man overveje at bruge decision trees. Dette kan dog lede til problemer med for meget varians...</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ede66538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, KBinsDiscretizer\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66179e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age     sex     bmi  children smoker     region      charges\n",
      "0   19  female  27.900         0    yes  southwest  16884.92400\n",
      "1   18    male  33.770         1     no  southeast   1725.55230\n",
      "2   28    male  33.000         3     no  southeast   4449.46200\n",
      "3   33    male  22.705         0     no  northwest  21984.47061\n",
      "4   32    male  28.880         0     no  northwest   3866.85520\n"
     ]
    }
   ],
   "source": [
    "# Definer alle de datasæt vi har og om de klassifikation eller ej\n",
    "iris = \"Iris.csv\" # Dette er et klassifikationsproblem!\n",
    "insurance = \"insurance.csv\"# Dette er et regressionsproblem!\n",
    "\n",
    "# Vælg en af datasættene her...\n",
    "current_dataset = insurance\n",
    "\n",
    "data = pd.read_csv(f\"../data/{current_dataset}\")\n",
    "\n",
    "# Print starten af dataen\n",
    "print(data.head())\n",
    "\n",
    "# Vælg om det er klassifikation eller ej\n",
    "is_classification = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "617e2aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Få alle ikke-numeriske kolonner til at være numeriske\n",
    "categorical_columns = [\"sex\", \"smoker\", \"region\"]\n",
    "target_column = \"charges\"\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "\n",
    "# Opdel i targets og features\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "# Definer størrelsen af testsættet...\n",
    "test_size = 0.2\n",
    "\n",
    "# Opdel i træning og test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c84d9aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tilfældet hvis vi er i gang med at lave klassifikation\n",
    "if is_classification is True:\n",
    "    # Definer en decision tree model:\n",
    "    # NB: Du må gerne definere ting såsom criterion og max_depth, men man behøver ikke\n",
    "    # Da ellers så bare får en default værdi hver især\n",
    "    dt_model = DecisionTreeClassifier()\n",
    "\n",
    "    # Definer en random forest classifer\n",
    "    # Her kan man også bestemme en masse hyperparametre, den vigtigste er dog\n",
    "    n_estimators = 100\n",
    "    # Som bestemmer hvor mange decision trees vi bruger\n",
    "    rf_model = RandomForestClassifier(n_estimators=n_estimators)\n",
    "\n",
    "# Tilfældet af at vi ikke skal klassificere noget...\n",
    "elif is_classification is False:    \n",
    "    # Her benytter vi os af decision tree regressors i stedet for...\n",
    "    # Der gælder lidt nogle andre regler, men principperne er i bund og grund det samme\n",
    "    dt_model = DecisionTreeRegressor()\n",
    "\n",
    "    n_estimators = 100\n",
    "    rf_model = RandomForestRegressor(n_estimators=n_estimators)\n",
    "\n",
    "# Træn modellerne\n",
    "dt_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Lav predictions på testsættet\n",
    "dt_preds = dt_model.predict(X_test)\n",
    "rf_preds = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7237fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Model Comparison:\n",
      "           Model  R² Score         RMSE          MAE\n",
      "0  Decision Tree  0.748932  6033.912952  2722.919084\n",
      "1  Random Forest  0.837805  4849.791079  2770.178396\n"
     ]
    }
   ],
   "source": [
    "# Lav fuld rapport af accuracies og sådan...\n",
    "if is_classification is True:\n",
    "    dt_accuracy = accuracy_score(y_test, dt_preds)\n",
    "    rf_accuracy = accuracy_score(y_test, rf_preds)\n",
    "\n",
    "    print(\"Decision Tree Classifier\")\n",
    "    print(\"Accuracy:\", dt_accuracy)\n",
    "    print(classification_report(y_test, dt_preds))\n",
    "\n",
    "    print(\"\\nRandom Forest Classifier\")\n",
    "    print(\"Accuracy:\", rf_accuracy)\n",
    "    print(classification_report(y_test, rf_preds))\n",
    "\n",
    "    # Optional: Compare in a simple table\n",
    "    comparison = pd.DataFrame({\n",
    "        \"Model\": [\"Decision Tree\", \"Random Forest\"],\n",
    "        \"Accuracy\": [dt_accuracy, rf_accuracy]\n",
    "    })\n",
    "\n",
    "    print(\"\\n📊 Model Comparison:\")\n",
    "    print(comparison)\n",
    "\n",
    "\n",
    "\n",
    "elif is_classification is False:\n",
    "    from sklearn.metrics import r2_score, root_mean_squared_error, mean_absolute_error\n",
    "    comparison = pd.DataFrame({\n",
    "        \"Model\": [\"Decision Tree\", \"Random Forest\"],\n",
    "        \"R² Score\": [r2_score(y_test, dt_preds), r2_score(y_test, rf_preds)],\n",
    "        \"RMSE\": [root_mean_squared_error(y_test, dt_preds), root_mean_squared_error(y_test, rf_preds)],\n",
    "        \"MAE\": [mean_absolute_error(y_test, dt_preds), mean_absolute_error(y_test, rf_preds)]\n",
    "    })\n",
    "\n",
    "    print(\"\\n📊 Model Comparison:\")\n",
    "    print(comparison)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-camp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
